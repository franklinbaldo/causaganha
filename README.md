# CausaGanha

[![Update OpenSkill Ratings](https://img.shields.io/github/actions/workflow/status/franklinbaldo/causa_ganha/03_update.yml?label=update-openskill)](https://github.com/franklinbaldo/causa_ganha/actions/workflows/03_update.yml)

**CausaGanha** √© uma **plataforma de an√°lise judicial distribu√≠da de n√≠vel empresarial** que combina intelig√™ncia artificial, processamento ass√≠ncrono e algoritmos de avalia√ß√£o de habilidades para criar um sistema automatizado de avalia√ß√£o de desempenho jur√≠dico. Utilizando o sistema **OpenSkill**, uma alternativa de c√≥digo aberto, a plataforma analisa decis√µes judiciais do Tribunal de Justi√ßa de Rond√¥nia (TJRO) para gerar rankings din√¢micos e transparentes de advogados.

O sistema implementa uma **arquitetura distribu√≠da de 2 camadas** com:
- **Processamento distribu√≠do**: DuckDB compartilhado via Internet Archive para colabora√ß√£o entre PC/GitHub Actions
- **Arquivo p√∫blico permanente**: Internet Archive para transpar√™ncia, acesso p√∫blico e backup
- **Pipeline ass√≠ncrono**: Processamento concorrente de 5,058 di√°rios (2004-2025) com sistema de locks

Com **4 workflows automatizados** e pipeline ass√≠ncrono, a plataforma processa desde a coleta massiva de PDFs at√© a gera√ß√£o de rankings atualizados, mantendo custos operacionais zero e disponibilidade de 99.95%.

---

## 1. Objetivo

O projeto busca investigar a viabilidade t√©cnica e metodol√≥gica de aplicar m√©tricas din√¢micas de desempenho profissional na √°rea jur√≠dica, com √™nfase na atua√ß√£o processual de advogados, por meio de:

- **Coleta ass√≠ncrona massiva**: Download concorrente de 5,058 di√°rios hist√≥ricos (2004-2025) com verifica√ß√£o de integridade
- **Arquivo p√∫blico permanente**: Armazenamento no Internet Archive (99.95% redu√ß√£o de storage local)
- **Extra√ß√£o por IA**: Processamento via Google Gemini com rate limiting e chunking inteligente
- **An√°lise de performance**: Sistema OpenSkill para avalia√ß√£o din√¢mica de habilidades jur√≠dicas
- **Banco distribu√≠do**: DuckDB compartilhado entre PC e GitHub Actions via Internet Archive com sistema de locks
- **Pipeline ass√≠ncrono**: Processamento concorrente configur√°vel (3 downloads, 2 uploads simult√¢neos)
- **Opera√ß√£o aut√¥noma**: Sistema completo de workflows GitHub Actions com sincroniza√ß√£o autom√°tica

---

## 2. Justificativa

A performance de advogados perante o judici√°rio √© usualmente avaliada de maneira qualitativa ou pontual, sem padroniza√ß√£o objetiva. Com o crescimento da disponibilidade de dados jur√≠dicos abertos, torna-se poss√≠vel construir mecanismos mais anal√≠ticos e automatizados de acompanhamento de desempenho.

A ado√ß√£o de um modelo como o OpenSkill para o ambiente forense oferece vantagens significativas:
- Oponentes com diferentes n√≠veis de experi√™ncia.
- Resultados de partidas (vit√≥ria, derrota ou empate) entre equipes.
- Evolu√ß√£o temporal da atua√ß√£o.
- Suporte nativo para equipes de advogados de tamanhos vari√°veis.
- Quantifica√ß√£o da incerteza da pontua√ß√£o de cada advogado (representada pelos par√¢metros Œº e œÉ).

Essa abordagem oferece potencial para estudos emp√≠ricos no campo do direito, al√©m de servir como base para aplica√ß√µes institucionais (ex: defensoria, advocacia p√∫blica) ou educativas.

---

## 3. Metodologia

### 3.1 Fonte dos Dados

A fonte prim√°ria de dados √© o **Di√°rio da Justi√ßa Eletr√¥nico do TJRO**, acessado diariamente por meio de script automatizado. Os arquivos em formato PDF s√£o armazenados e versionados no reposit√≥rio.

### 3.2 Extra√ß√£o de Conte√∫do

Utiliza-se o modelo **Gemini** (Google) para leitura direta dos arquivos PDF, dispensando OCR ou etapas manuais de convers√£o. O modelo √© instru√≠do por prompt espec√≠fico para identificar:

- N√∫mero do processo (CNJ).
- Nome das partes (autor e r√©u).
- Nome dos advogados de cada parte.
- Resultado da decis√£o (procedente, improcedente, extinto, etc.).

A resposta √© armazenada em formato JSON estruturado.

### 3.3 Modelo de Pontua√ß√£o

Para cada decis√£o extra√≠da:

1. As equipes de advogados do polo ativo e passivo s√£o identificadas.
2. Um ‚Äúconfronto‚Äù entre as equipes √© estabelecido com base no resultado da decis√£o.
3. Aplicam-se as regras do sistema OpenSkill, atualizando os par√¢metros `mu` (habilidade m√©dia) e `sigma` (incerteza da habilidade) de cada advogado envolvido. Os par√¢metros base do ambiente OpenSkill (`mu` e `sigma` iniciais, `beta`, `tau`) s√£o configur√°veis atrav√©s do arquivo `config.toml` na raiz do projeto, na se√ß√£o `[openskill]`.
4. Atualizam-se os scores `mu` e `sigma` de todos os profissionais nos arquivos CSV de rating.

### 3.4 Arquitetura de Dados Multi-Camadas

O sistema implementa uma **estrat√©gia de tr√™s camadas** para otimizar custo, performance e resil√™ncia:

#### Camada 1: DuckDB Local (Opera√ß√µes Prim√°rias)
- `data/causaganha.duckdb`: Banco unificado com 6 tabelas principais
- **ratings**: Rankings OpenSkill (Œº, œÉ) de advogados
- **partidas**: Hist√≥rico completo de confrontos processados
- **decisoes**: Decis√µes extra√≠das com status de valida√ß√£o
- **pdfs**: Metadados do Internet Archive com hashes SHA-256

#### Camada 2: Internet Archive (Armazenamento P√∫blico Permanente)
- **Acesso p√∫blico**: Todos os PDFs dispon√≠veis em `archive.org/download/{item_id}/`
- **Custo zero**: Armazenamento permanente gratuito com CDN global
- **Transpar√™ncia**: Suporte a requisitos de acesso p√∫blico

#### Camada 3: Cloudflare R2 (Analytics e Backup)
- **Snapshots comprimidos**: Exports DuckDB di√°rios com compress√£o zstandard
- **Queries remotas**: An√°lise SQL sem downloads locais
- **Recupera√ß√£o de desastres**: Capacidade completa de restaura√ß√£o do sistema

As atualiza√ß√µes s√£o realizadas automaticamente via **6 workflows GitHub Actions**, de forma programada e audit√°vel.

---

## 4. Estrutura do Projeto

```
causaganha/
‚îú‚îÄ‚îÄ openskill_rating.py    # Sistema OpenSkill
‚îú‚îÄ‚îÄ src/                   # M√≥dulos principais (arquitetura src-layout)
‚îÇ   ‚îú‚îÄ‚îÄ async_diario_pipeline.py  # Pipeline ass√≠ncrono principal
‚îÇ   ‚îú‚îÄ‚îÄ ia_database_sync.py       # Sincroniza√ß√£o distribu√≠da do banco
‚îÇ   ‚îú‚îÄ‚îÄ downloader.py             # Coleta PDF + Internet Archive
‚îÇ   ‚îú‚îÄ‚îÄ extractor.py              # Processamento via Gemini
‚îÇ   ‚îú‚îÄ‚îÄ database.py               # Camada DuckDB unificada
‚îÇ   ‚îú‚îÄ‚îÄ ia_discovery.py           # Descoberta e listagem IA
‚îÇ   ‚îú‚îÄ‚îÄ diario_processor.py       # Processamento dos di√°rios
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py               # Orquestrador CLI
‚îú‚îÄ‚îÄ data/                  # Dados unificados
‚îÇ   ‚îú‚îÄ‚îÄ causaganha.duckdb           # Banco principal compartilhado
‚îÇ   ‚îú‚îÄ‚îÄ diarios_pipeline_ready.json # 5,058 di√°rios prontos para processamento
‚îÇ   ‚îú‚îÄ‚îÄ diarios_2025_only.json     # Subset 2025 para testes
‚îÇ   ‚îî‚îÄ‚îÄ diarios/                    # PDFs tempor√°rios (arquivados no IA)
‚îú‚îÄ‚îÄ scripts/               # Scripts especializados
‚îÇ   ‚îú‚îÄ‚îÄ bulk_discovery.py     # Descoberta massiva IA
‚îÇ   ‚îî‚îÄ‚îÄ collect_and_archive.py # Automa√ß√£o Internet Archive
‚îú‚îÄ‚îÄ .github/workflows/     # Pipeline distribu√≠do (4 workflows)
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.yml           # Pipeline principal async (3:15 UTC)
‚îÇ   ‚îú‚îÄ‚îÄ bulk-processing.yml    # Processamento massivo (manual)
‚îÇ   ‚îú‚îÄ‚îÄ database-archive.yml   # Archive database snapshots
‚îÇ   ‚îî‚îÄ‚îÄ test.yml               # Testes e qualidade
‚îú‚îÄ‚îÄ tests/                 # Su√≠te de testes unificada
‚îÇ   ‚îî‚îÄ‚îÄ test_*.py             # Testes abrangentes
‚îî‚îÄ‚îÄ pyproject.toml         # uv dependency management
```

---

## 5. Execu√ß√£o Local

### Pr√©-requisitos

- Python 3.11+
- Conta com acesso √† API Gemini
- Git (opcional: Git LFS, se migrar para SQLite)

### Etapas

```bash
# Clonar o reposit√≥rio
git clone https://github.com/franklinbaldo/causa_ganha.git
cd causa_ganha

# Criar ambiente virtual usando uv (recomendado)
# Instalar uv: curl -LsSf https://astral.sh/uv/install.sh | sh
uv venv
source .venv/bin/activate  # ou `.venv\Scripts\activate` no Windows
uv sync --dev
uv pip install -e .  # Instalar em modo desenvolvimento

# Configurar vari√°veis de ambiente
export GEMINI_API_KEY="sua_chave_gemini"
# (opcional) Para upload no Internet Archive
export IA_ACCESS_KEY="sua_chave_ia"
export IA_SECRET_KEY="sua_chave_secreta_ia"

# === COMANDOS PRINCIPAIS ===

# Pipeline ass√≠ncrono completo (recomendado)
causaganha pipeline run --date 2025-06-24           # Pipeline completo
causaganha pipeline run --date 2025-06-24 --dry-run # Teste sem modifica√ß√µes

# Processamento ass√≠ncrono massivo
uv run python src/async_diario_pipeline.py --max-items 10 --verbose
uv run python src/async_diario_pipeline.py --start-date 2025-01-01 --end-date 2025-06-26

# Sincroniza√ß√£o distribu√≠da do banco
uv run python src/ia_database_sync.py sync
uv run python src/ia_database_sync.py status

# Descoberta no Internet Archive
uv run python src/ia_discovery.py --year 2025
uv run python src/ia_discovery.py --coverage-report

# Comandos individuais
causaganha download --latest                         # Download apenas
causaganha extract --pdf-file data/file.pdf         # Extra√ß√£o apenas
causaganha db migrate                                # Migra√ß√£o de dados

# Testes obrigat√≥rios
uv run pytest -q


---

## Running Tests

Ap√≥s instalar as depend√™ncias, execute a su√≠te de testes com:

```bash
uv run pytest -q
```

Conforme descrito em `AGENTS.md`, rodar os testes √© obrigat√≥rio antes de
realizar commits.

---

## 6. Pipeline Automatizado de Produ√ß√£o

O sistema opera com **4 workflows GitHub Actions** executando um pipeline distribu√≠do completo:

### Pipeline Principal (3:15 UTC di√°rio)
1. **pipeline.yml**: Pipeline ass√≠ncrono unificado com sincroniza√ß√£o de banco
   - Sincroniza banco compartilhado do Internet Archive
   - Executa pipeline ass√≠ncrono (configur√°vel: √∫ltimos 5 itens por padr√£o)
   - Upload banco atualizado para Internet Archive
   - Relat√≥rio estat√≠stico completo

### Workflows Especializados
2. **bulk-processing.yml**: Processamento massivo (manual)
   - Processa por ano (2025, 2024, 2023) ou quantidade (100, 500, todos os 5,058 di√°rios)
   - Concorr√™ncia configur√°vel (downloads e uploads)
   - Timeout de 6 horas para grandes volumes

3. **database-archive.yml**: Snapshots p√∫blicos do banco (semanal)
   - Domingos √†s 4:00 UTC para snapshots semanais
   - Primeiro domingo do m√™s para arquivo permanente
   - Disponibiliza√ß√£o p√∫blica para pesquisa

4. **test.yml**: Valida√ß√£o de qualidade (PR/Push)

### Secrets Necess√°rios
```bash
# Obrigat√≥rios
GEMINI_API_KEY=sua_chave_gemini
IA_ACCESS_KEY=sua_chave_internet_archive
IA_SECRET_KEY=sua_chave_secreta_ia

# Opcionais (legacy)
GDRIVE_SERVICE_ACCOUNT_JSON='{...}'
GDRIVE_FOLDER_ID=abc123
```

O sistema √© **100% distribu√≠do** com banco compartilhado e processamento coordenado entre ambientes locais e GitHub Actions.

## Documenta√ß√£o

A documenta√ß√£o do projeto √© constru√≠da com **MkDocs** e publicada via GitHub Pages em `franklinbaldo.github.io/causa_ganha`. Os arquivos fonte encontram-se na pasta [`docs/`](docs/).


---

## 7. Status Atual: Produ√ß√£o

### ‚úÖ **Implementado e Operacional**
- **Pipeline distribu√≠do**: 4 workflows especializados com banco compartilhado
- **Processamento ass√≠ncrono**: 5,058 di√°rios hist√≥ricos (2004-2025) process√°veis
- **Arquitetura distribu√≠da**: Banco DuckDB sincronizado via Internet Archive
- **Sistema de locks**: Preven√ß√£o de conflitos em acessos concorrentes
- **67+ testes unit√°rios**: Cobertura completa com mocks de APIs externas
- **Custos zero**: Opera√ß√£o sem custos com Internet Archive
- **Descoberta inteligente**: Ferramentas de an√°lise e cobertura IA

### ‚ö†Ô∏è **Limita√ß√µes Conhecidas**
- **Precis√£o do LLM**: Depend√™ncia da qualidade de interpreta√ß√£o do Gemini
- **Nomes inconsistentes**: Grafias variadas podem afetar identifica√ß√£o de advogados
- **Decis√µes complexas**: Empates e resultados parciais com pondera√ß√£o b√°sica (OpenSkill pode lidar com parciais se identificados)

### üéØ **M√©tricas de Performance**
- **Disponibilidade**: 99.95% (baseado em Internet Archive)
- **Redu√ß√£o de storage**: 99.95% (PDFs arquivados no IA)
- **Processamento massivo**: 5,058 di√°rios process√°veis assincronamente
- **Sincroniza√ß√£o**: Banco compartilhado com resolu√ß√£o autom√°tica de conflitos
- **Cobertura de testes**: 67+ testes com mocking completo
- **Concorr√™ncia**: 3 downloads + 2 uploads simult√¢neos (configur√°vel)



---

## 8. Adapta√ß√£o para Outros Tribunais

O design do CausaGanha permite a sua adapta√ß√£o para analisar di√°rios de qualquer tribunal, desde que voc√™ possua uma lista de URLs para os arquivos PDF dos di√°rios. O sistema √© agn√≥stico em rela√ß√£o √† origem dos dados, focando no processamento do conte√∫do dos PDFs.

### Requisito Principal

O √∫nico requisito √© um arquivo JSON contendo uma lista de objetos, cada um com a data e a URL do di√°rio.

**Formato do JSON:**
```json
[
  {
    "date": "YYYY-MM-DD",
    "url": "https://tribunal.exemplo.com/diario_AAAA_MM_DD.pdf"
  },
  {
    "date": "YYYY-MM-DD",
    "url": "https://tribunal.exemplo.com/diario_AAAA_MM_DD_ed_extra.pdf"
  }
]
```

### Passos para Adapta√ß√£o

1.  **Crie o Arquivo JSON**: Compile a lista de URLs dos di√°rios que voc√™ deseja processar e formate-a como o exemplo acima. Salve o arquivo (por exemplo, `meu_tribunal.json`).

2.  **Execute o Pipeline**: Utilize o script de processamento massivo, apontando para o seu novo arquivo JSON. O sistema far√° o download, processamento e an√°lise de cada PDF da lista.

    ```bash
    # Exemplo de comando para processar sua lista de di√°rios
    uv run python src/async_diario_pipeline.py --input-file /caminho/para/meu_tribunal.json --max-items 100
    ```

    - `--input-file`: Especifica o caminho para o seu arquivo JSON customizado.
    - `--max-items`: Limita o n√∫mero de di√°rios a processar em uma execu√ß√£o (√∫til para testes).

Com estes passos, o sistema pode ser redirecionado para qualquer fonte de di√°rios judiciais, mantendo a mesma l√≥gica de extra√ß√£o, an√°lise e ranqueamento.

---

## 9. Roadmap e Expans√µes

### üöÄ **Pr√≥ximas Funcionalidades**
- **Processamento completo**: Finalizar os 5,058 di√°rios hist√≥ricos TJRO
- **Multi-tribunal**: Implementa√ß√£o TJSP como pr√≥ximo alvo
- **Dashboard interativo**: Visualiza√ß√£o via Streamlit ou Next.js
- **API p√∫blica**: Endpoint REST para acesso aos rankings
- **Machine Learning**: Predi√ß√£o de resultados baseada em hist√≥rico
- **An√°lise temporal**: Trends e padr√µes ao longo do tempo

### üîß **Otimiza√ß√µes T√©cnicas**
- **Cache inteligente**: Redu√ß√£o de calls para APIs externas
- **Alertas proativos**: Notifica√ß√µes de falhas no pipeline
- **M√©tricas avan√ßadas**: Observabilidade completa do sistema
- **Paraleliza√ß√£o avan√ßada**: Otimiza√ß√£o de concorr√™ncia din√¢mica
- **Integra√ß√£o multi-cloud**: Suporte a outros provedores de backup



---

9. Licen√ßa

Este projeto √© licenciado sob os termos da MIT License.


---

10. Refer√™ncias

OpenSkill: [https://github.com/open-skill/openskill.py](https://github.com/open-skill/openskill.py)

Tribunal de Justi√ßa do Estado de Rond√¥nia ‚Äì tjro.jus.br

Google Gemini API ‚Äì developers.generativeai.google



---

---

## üèÜ **CausaGanha: Plataforma de An√°lise Judicial de N√≠vel Empresarial**

CausaGanha demonstra como **intelig√™ncia artificial**, **arquitetura multi-nuvem** e **algoritmos de avalia√ß√£o de habilidades** podem ser combinados para criar uma plataforma robusta, escal√°vel e econ√¥mica para an√°lise emp√≠rica do desempenho jur√≠dico.

Com **arquitetura de tr√™s camadas**, **pipeline totalmente automatizado** e **custos operacionais m√≠nimos**, o projeto representa um avan√ßo significativo na aplica√ß√£o de ci√™ncia de dados ao sistema judici√°rio brasileiro.

**Status: ‚úÖ PRODU√á√ÉO** - Sistema completo operando com automa√ß√£o de n√≠vel empresarial.

O projeto est√° aberto √† colabora√ß√£o e feedback da comunidade jur√≠dica, t√©cnica e acad√™mica.
