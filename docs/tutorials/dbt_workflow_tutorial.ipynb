{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbt Workflow Tutorial for CausaGanha\n",
    "\n",
    "This tutorial guides you through setting up and using `dbt-duckdb` within the CausaGanha project. It is based on the plan outlined in `docs/plans/dtb.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Why dbt-duckdb?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CausaGanha project uses `dbt-duckdb` for managing its database transformations and schema. Here's why, based on the project's planning documents (`docs/plans/dtb.md`):\n",
    "\n",
    "- **Unified Tooling**: `dbt` handles Data Definition Language (DDL), tests, lineage documentation, and CI drift-checks with a single binary.\n",
    "- **Native DuckDB Support**: The `dbt-duckdb` adapter is maintained by DuckDB core developers and supports full SQL, including operations on Parquet/CSV external tables.\n",
    "- **Reproducibility & Idempotency**: Models are rebuilt from source on every `dbt build`. This means development environments can be easily reset, and production builds are idempotent.\n",
    "- **Built-in Data Quality**: Tests for issues like null values or non-unique entries can be defined directly alongside model code, ensuring data integrity.\n",
    "- **Future-Proof**: If the project outgrows an embedded DuckDB file, the same dbt models can be used with other backends like MotherDuck or PostgreSQL with minimal changes to the dbt profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Install dbt and dbt-duckdb\n",
    "\n",
    "If you haven't already, you'll need to install `dbt-duckdb`. This project uses `uv` for Python package management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install \"dbt-duckdb~=1.9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 dbt Project Structure\n",
    "\n",
    "In CausaGanha, the dbt project is located in the `dbt/` directory at the root of the repository. If you were starting a new dbt project, you might run `dbt init your_project_name --adapter duckdb`. For this project, the structure is already established."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify the dbt project directory exists. The following command should list its contents if you are running this notebook from the `docs/tutorials/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../../dbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see files like `dbt_project.yml` and directories like `models/`, `seeds/`, `tests/` etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Configure `profiles.yml`\n",
    "\n",
    "dbt uses a `profiles.yml` file to store connection configurations. This file is typically located in `~/.dbt/`. You need to ensure it's configured to point to the CausaGanha project's DuckDB database.\n",
    "\n",
    "Here's the relevant configuration from `docs/plans/dtb.md`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# This content goes into your ~/.dbt/profiles.yml\n",
    "\n",
    "causa_ganha:\n",
    "  target: local\n",
    "  outputs:\n",
    "    local:\n",
    "      type: duckdb\n",
    "      path: /path/to/your/causa_ganha_repo/data/causaganha.duckdb\n",
    "      # Ensure this 'path' is an absolute path or a path relative to where you run dbt commands from,\n",
    "      # if you are not using the --profiles-dir option with dbt.\n",
    "      # For consistency, using an absolute path is often easier for local setup.\n",
    "```\n",
    "**Important:** \n",
    "- Replace `/path/to/your/causa_ganha_repo/` with the actual absolute path to your cloned CausaGanha repository.\n",
    "- The profile name `causa_ganha` here must match the `profile` setting in the `dbt/dbt_project.yml` file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After configuring `~/.dbt/profiles.yml`, you can test your setup. From the root of the CausaGanha repository, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you are in the root of the CausaGanha repository to run this command\n",
    "# If this notebook is in docs/tutorials/, you would go up two directories.\n",
    "# For demonstration, we assume you'd run this in your terminal from the repo root.\n",
    "!cd ../.. && dbt debug --project-dir dbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If successful, this command will check your `profiles.yml` and `dbt_project.yml` and attempt to connect to the database. It will create `data/causaganha.duckdb` if it doesn't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Repository Layout for dbt\n",
    "\n",
    "The `docs/plans/dtb.md` plan outlines the following structure related to dbt:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ".\n",
    "├── data/                       # .duckdb file lives here, ignored by Git\n",
    "│   └── causaganha.duckdb\n",
    "├── dbt/                        # dbt project root\n",
    "│   ├── models/\n",
    "│   │   ├── staging/            # 1-to-1 raw ingests from source data\n",
    "│   │   ├── marts/              # Final analytical tables (e.g., rankings)\n",
    "│   │   └── seeds/              # CSV reference data loaded via dbt seed\n",
    "│   ├── tests/                  # Custom SQL tests (generic tests are usually in .yml files)\n",
    "│   ├── macros/                 # Custom macros \n",
    "│   └── dbt_project.yml         # Main dbt project configuration file\n",
    "├── src/                        # Python application code (CLI, API, etc.)\n",
    "└── .github/workflows/          # CI pipeline configurations\n",
    "```\n",
    "**Key points:**\n",
    "- The actual DuckDB database file (`data/causaganha.duckdb`) is listed in `.gitignore` and is not committed to the repository.\n",
    "- All dbt model definitions, tests, and configurations are stored within the `dbt/` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Defining Models & Tests\n",
    "\n",
    "In dbt, transformations are defined as SQL `SELECT` statements called **models**. Tests ensure data quality and integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Staging Model\n",
    "\n",
    "A staging model typically performs light cleaning and preparation of raw data. For example, a model `dbt/models/staging/tjro_diary.sql` might look like this (conceptual example from `dtb.md`):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- File: dbt/models/staging/stg_tjro_diario.sql\n",
    "\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "SELECT\n",
    "    dj.id,\n",
    "    dj.date,\n",
    "    dj.url_archive,\n",
    "    dj.file_hash\n",
    "FROM read_parquet('path/to/source/raw/tjro_diary_*.parquet') dj -- Replace with actual source data loading, e.g. {{ source('my_source', 'tjro_raw_diaries') }}\n",
    "```\n",
    "**Note:** The `read_parquet` function and path are illustrative. In a real dbt project, you'd typically use `{{ source('source_name', 'table_name') }}` to refer to raw data sources defined in a `.yml` file, or `{{ ref('another_model') }}` to refer to other dbt models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Mart Model\n",
    "\n",
    "A mart model represents data ready for analytics or reporting. For instance, `dbt/models/marts/advocate_ranking.sql` could calculate advocate rankings:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "-- File: dbt/models/marts/advocate_ranking.sql\n",
    "\n",
    "{{ config(materialized='table') }}\n",
    "\n",
    "WITH extracted_data AS (\n",
    "    SELECT\n",
    "        (partes->>'advocate')::VARCHAR AS advocate, -- Example: extract advocate from JSON\n",
    "        (partes->>'outcome')::VARCHAR  AS outcome   -- Example: extract outcome from JSON\n",
    "    FROM {{ ref('stg_tjro_diario') }} -- Referencing the staging model\n",
    "    WHERE partes IS NOT NULL -- Ensure 'partes' column is not null before trying to extract from it\n",
    ")\n",
    "SELECT\n",
    "    advocate,\n",
    "    -- elo_ranking(outcome) AS elo -- Placeholder for actual ranking logic\n",
    "    COUNT(*) AS total_cases,\n",
    "    SUM(CASE WHEN outcome = 'favorable' THEN 1 ELSE 0 END) AS favorable_outcomes\n",
    "FROM extracted_data\n",
    "WHERE advocate IS NOT NULL AND advocate <> '' -- Ensure advocate is not null or empty\n",
    "GROUP BY advocate\n",
    "ORDER BY favorable_outcomes DESC, total_cases DESC;\n",
    "```\n",
    "**Note:** The `elo_ranking(outcome)` is a placeholder for the actual OpenSkill ranking logic which might be implemented as a User-Defined Function (UDF) or a dbt macro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Tests\n",
    "\n",
    "dbt allows you to define tests in `.yml` files alongside your models. For example, to test the `advocate_ranking` model, you could create `dbt/models/marts/advocate_ranking.yml`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# File: dbt/models/marts/advocate_ranking.yml\n",
    "\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "  - name: advocate_ranking # This must match the .sql filename (advocate_ranking.sql)\n",
    "    description: \"Table containing advocate rankings based on case outcomes.\"\n",
    "    columns:\n",
    "      - name: advocate\n",
    "        description: \"The name or identifier of the advocate.\"\n",
    "        tests:\n",
    "          - not_null\n",
    "          - unique\n",
    "      - name: total_cases\n",
    "        description: \"Total number of cases for the advocate.\"\n",
    "        tests:\n",
    "          - not_null\n",
    "          - dbt_utils.accepted_range:\n",
    "              min_value: 0\n",
    "      - name: favorable_outcomes\n",
    "        description: \"Number of favorable outcomes for the advocate.\"\n",
    "        tests:\n",
    "          - not_null\n",
    "          - dbt_utils.accepted_range:\n",
    "              min_value: 0\n",
    "```\n",
    "This configuration defines that the `advocate` column in the `advocate_ranking` table should not be null and should be unique. It also adds range checks for counts. dbt will automatically generate and run these tests during `dbt build` or `dbt test`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Running dbt Locally\n",
    "\n",
    "Once models and tests are defined, you can run dbt commands from the root of the CausaGanha repository, specifying the project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build All Models and Run Tests\n",
    "The `dbt build` command will run all your models, execute tests, and potentially build documentation and run snapshots if configured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you are in the repo root directory for this command\n",
    "!cd ../.. && dbt build --project-dir dbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Specific Models\n",
    "You can run a subset of models using the `--select` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run only models in the staging directory (models within dbt/models/staging)\n",
    "!cd ../.. && dbt run --select staging --project-dir dbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Specific Models\n",
    "Similarly, you can test specific models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the advocate_ranking model\n",
    "!cd ../.. && dbt test --select advocate_ranking --project-dir dbt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetting Local Database (During Alpha/Development)\n",
    "\n",
    "The `dtb.md` plan mentions a script for easily resetting the database during development, which is useful when model structures change frequently. This might be `scripts/db/reset_dbt_database.sh`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/usr/bin/env bash\n",
    "# File: scripts/db/reset_dbt_database.sh (example content)\n",
    "set -e\n",
    "\n",
    "# Assuming this script is run from the repository root\n",
    "DB_FILE=\"data/causaganha.duckdb\"\n",
    "DBT_PROJECT_DIR=\"dbt\"\n",
    "\n",
    "echo \"Removing database file: $DB_FILE\"\n",
    "rm -f \"$DB_FILE\"\n",
    "\n",
    "echo \"Rebuilding dbt models...\"\n",
    "dbt build --project-dir \"$DBT_PROJECT_DIR\"\n",
    "\n",
    "echo \"✅ Fresh DB built and models materialized.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script would typically be run from the repository root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you are in the repo root directory and the script is executable\n",
    "# !cd ../.. && sh ./scripts/db/reset_dbt_database.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, this functionality might be integrated into the project's CLI, e.g., `uv run causaganha db reset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ../.. && uv run causaganha db reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. CLI Integration\n",
    "\n",
    "The `docs/plans/dtb.md` plan suggests integrating dbt commands into the existing CausaGanha CLI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the `causaganha db migrate` command, which previously might have used Alembic, could be updated to call `dbt build`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Conceptual Python code for CLI command in src/cli.py or similar\n",
    "import subprocess\n",
    "\n",
    "def db_migrate():\n",
    "    \"\"\"Rebuild dbt models to the latest state.\"\"\"\n",
    "    try:\n",
    "        # Assuming dbt is in PATH and commands are run from repo root\n",
    "        subprocess.check_call([\"dbt\", \"build\", \"--project-dir\", \"dbt\"])\n",
    "        print(\"✅ dbt models built successfully.\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Error during dbt build: {e}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"❌ Error: dbt command not found. Is dbt installed and in your PATH?\")\n",
    "```\n",
    "With such integration, users can continue using familiar CLI commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd ../.. && uv run causaganha db migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. CI Pipeline (GitHub Actions)\n",
    "\n",
    "A Continuous Integration (CI) pipeline, typically defined in `.github/workflows/`, would automate the process of building and testing dbt models on every push or pull request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example workflow (e.g., `.github/workflows/dbt_build_test.yml`, based on `dtb.md` Section 6) might include steps to:\n",
    "1. Checkout code.\n",
    "2. Set up Python and install dependencies (including `dbt-duckdb`).\n",
    "3. Run `dbt build --project-dir dbt` to build models and run tests.\n",
    "4. Optionally, perform a \"drift check\" to ensure all defined models are materialized in the database, failing the build if there are unbuilt models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# Example .github/workflows/dbt_build_test.yml (simplified from dtb.md)\n",
    "name: CausaGanha DBT Build & Test\n",
    "\n",
    "on: [push, pull_request]\n",
    "\n",
    "jobs:\n",
    "  build_and_test_dbt:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v4\n",
    "\n",
    "      - name: Set up Python\n",
    "        uses: actions/setup-python@v5\n",
    "        with:\n",
    "          python-version: \"3.12\" # Or your project's Python version\n",
    "\n",
    "      - name: Install uv\n",
    "        run: curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "\n",
    "      - name: Install dbt dependencies\n",
    "        run: uv pip install \"dbt-duckdb~=1.9\"\n",
    "\n",
    "      - name: Run dbt build\n",
    "        run: dbt build --project-dir dbt\n",
    "        env:\n",
    "          # CI might need a specific profiles.yml or environment variables for path configuration\n",
    "          DBT_PROFILES_DIR: ./.dbt_ci # Example: use a CI-specific profiles dir\n",
    "\n",
    "      # Optional: Add a step for schema drift check if needed\n",
    "```\n",
    "A `.dbt_ci/profiles.yml` might be needed, configured to use a path like `data/ci_causaganha.duckdb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optional dbt Features\n",
    "\n",
    "dbt offers several other powerful features that can be adopted as needed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Seeds**: Useful for managing small, static lookup tables (e.g., country codes, status lists). Place CSV files in the `dbt/seeds/` directory and run `dbt seed --project-dir dbt` to load them into your database. These can then be referenced in models using `{{ ref('seed_file_name') }}`.\n",
    "\n",
    "- **Snapshots**: Help track changes to mutable data over time (Slowly Changing Dimensions). For example, if an advocate's status changes, snapshots can capture the history of these changes.\n",
    "\n",
    "- **Documentation**: dbt can automatically generate a website documenting your project, including model definitions, column descriptions, and a Directed Acyclic Graph (DAG) of model dependencies. Run `dbt docs generate --project-dir dbt` to create the documentation JSON, and then `dbt docs serve --project-dir dbt` to view it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Generate and serve dbt documentation (run from repo root)\n",
    "# !cd ../.. && dbt docs generate --project-dir dbt\n",
    "# !cd ../.. && dbt docs serve --project-dir dbt --port 8081 # Use a different port if 8080 is taken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial covered the basics of setting up and using dbt with DuckDB in the CausaGanha project. Refer to the official [dbt documentation](https://docs.getdbt.com/) and the `docs/plans/dtb.md` file for more detailed information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
